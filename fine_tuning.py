from tensorflow.keras.models import load_model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing import image_dataset_from_directory

# ğŸ” DiretÃ³rios
finetune_dir = "fine_tuning_split/finetune"  # Caminho relativo
img_size = (128, 128)
batch_size = 32

# ğŸ” Carregar dados de fine-tuning
finetune_dataset = image_dataset_from_directory(
    finetune_dir,
    image_size=img_size,
    batch_size=batch_size,
    shuffle=True
)

# ğŸ” Normalizar imagens
finetune_dataset = finetune_dataset.map(lambda x, y: (x / 255.0, y))

# ğŸ” Carregar modelo existente
model = load_model("modelo_alzheimer.keras")

# ğŸ” Tornar todas as camadas treinÃ¡veis
for layer in model.layers:
    layer.trainable = True

# ğŸ” Recompilar com learning rate mais baixo
model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

# ğŸ” Callback para evitar overfitting
early_stop = EarlyStopping(monitor="loss", patience=3, restore_best_weights=True)

# ğŸ” Treinar
history = model.fit(
    finetune_dataset,
    epochs=10,
    callbacks=[early_stop]
)

# ğŸ” Guardar novo modelo
model.save("modelo_alzheimer_finetuned.keras")
print("âœ… Fine-tuning concluÃ­do com sucesso.")
